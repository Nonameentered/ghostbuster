New Eye-Movement Control System Allows Severely Handicapped to Communicate via Computer

Scientists at Stanford University have developed a new assistive technology that enables people with severe physical disabilities to communicate quickly and accurately using just their eye movements. The system, called "EyeSwitch," tracks a person's eye movements using a high-resolution camera and an advanced machine learning algorithm. The user can then control an on-screen keyboard or other interface using a series of eye blinks and dwellsâ€”looking steadily at a region of the screen for a specified time period.  

The EyeSwitch system was tested with 15 people who have conditions like amyotrophic lateral sclerosis (ALS), brainstem strokes, and spinal cord injuries that prevent them from using their hands. After just 15-30 minutes of training, the participants were able to enter text, surf the web, check email, and control a smart home environment with 95-98% accuracy, a rate comparable to their able-bodied peers. "The level of performance we saw with the EyeSwitch system shows its potential to give a voice back to those who thought they had lost it forever," said James Parker, PhD, a senior author of the study and an assistant professor of neurosurgery at Stanford.  

For the participants, EyeSwitch represented a dramatic improvement over existing assistive technologies like gaze-controlled keyboards that require the user to look at each letter or region of the screen individually. The advanced machine learning algorithm powering EyeSwitch is able to interpret the user's intended target even when their gaze moves rapidly between or slightly off of each selection on the screen. "It works in a much more natural, intuitive way and allows people to communicate at a pace that's similar to speaking face-to-face," said Margaret Guan, an occupational therapist who works with ALS patients and participated in the evaluation of EyeSwitch.   

While the results are promising, the researchers caution that the study was small and short-term. Additional testing is needed to evaluate EyeSwitch's performance over longer periods of continuous use. The current prototype also requires the user to be very still while controlling the interface, which may be difficult for some patients over time. The research team plans to continue refining the system to improve its accuracy, allow some head movement, and develop an interface that can control not just computers but also electric wheelchairs, smart home devices, and other assistive technologies that provide more independence and quality of life for people with disabilities.