Heuristic evaluation is a usability engineering method for finding the usability problems in a user interface design so that they can be attended to as part of an iterative design process. Heuristic evaluation involves having a group of evaluators examine the interface and judge its compliance with recognized usability principles (the "heuristics") (
The problem with using heuristics is that they can be interpreted subjectively. That makes it extremely significant to be conducted on a group of people, as a single participant will not be able to find all usability problems in examined interface. In a set of expert evaluators, each of individuals concentrates on different issues, using their own experiences and knowledge.
Figure 1 shows an example from a case study of heuristic evaluation where 19 evaluators were supposed to find 16 usability problems in a voice response system allowing customers access to their bank accounts (Nielsen 1992). Each row represents one of the 19 evaluators and each column represents one of the 16 usability problems. Each square shows whether the evaluator represented by the row found the usability problem represented by the column:
The black square- the problem was found
The white square- the evaluator did not find the problem.
The rows have been sorted in such a way that the most successful evaluators are at the bottom and the least successful are at the top. The columns have been sorted in such a way that the usability problems that are the easiest to find are to the right and the usability problems that are the most difficult to find are to the left.
The figure clearly shows that some usability problems are so easy to find that they are found by almost everybody, but there are also some problems that are found by very few evaluators. Furthermore, it is impossible to identify the best evaluator and rely exclusively on that person's findings as:
it is not necessarily true that the same person will be the best evaluator every time.
some of the hardest-to-find usability problems were found by evaluators who do not otherwise find many easy-to-find usability problems.
That is why, it is necessary to involve multiple evaluators in any heuristic evaluation. General recommendation is to use three to five evaluators since using larger number does not improve result of the tests in comparison to the extra costs which would be required.
In order to ensure independent and unbiased results heuristic evaluation is performed by having each individual evaluator inspecting the interface alone. Only after whole group of experts has been examined, are the evaluators allowed to communicate and have their findings amassed. The results can be traced as written reports (after the test) or verbalized remarks (during the examination). In my test I record the comments during the test, in my opinion that should make my work more effective.
Typically, a heuristic evaluation session for an individual evaluator lasts one or two hours. Longer evaluation sessions might be boring for the tester, and therefore the test will not be very effective. If the evaluation subject is a large or very complicated interface with a substantial number of dialogue elements it would be better to split the test into several smaller sessions, each concentrating on a part of the interface.
During the evaluation session, the evaluator goes through the interface several times and inspects the various dialogue elements and compares them with the list of heuristics supplied by examiner. These heuristics are general rules that seem to describe general properties of usable interfaces. In addition the list of general heuristics can be extended by developed category-specific heuristics that apply to a specific class of products, or by the evaluator himself. One way of building a supplementary list of category-specific heuristics is to perform competitive analysis and user testing of existing products in the given category and try to abstract principles to explain the usability problems that are found (Dykstra 1993).
It is highly recommended that evaluators go through the interface at least twice, however standard says, that they decide on their own how they want to proceed with evaluating the interface. The first pass should give them general scope of the system and the way it works. The second (next) pass allows the evaluator to concentrate on specific interface elements and flaws while knowing how they fit into the entire system. (
If the system is intended as intuitive use interface for the general population or if the evaluators are field experts, it should be possible to let the evaluators use the system without further assistance. If the system is sophisticated and the evaluators are fairly inexperienced with the area the system works in, it will be necessary to help the evaluators e.g. by supplying them with typical usage scenario. Such scenario will list the different steps for a user to take to perform a sample set of realistic tasks.
One has to remember that it is not enough for evaluators to simply say that they do not like something. They must explain why they do not like it with reference to usability principles. Every tester provides subjective result of using the heuristic evaluation method, which is a list of usability problems in the user interface with references to heuristics that were dishonoured by the design. The evaluators should be as specific as possible and list each usability problem separately. There are two main reasons to note each problem separately:
even if it was fully replaced with a new design, there is a risk of repeating some problematic aspect of a dialogue element, unless one is aware of all its problems.
it may not be possible to fix all usability problems in an interface element or to replace it with a new design, but it could still be possible to fix some of the problems if they are all known.
Heuristic evaluation does not offer a systematic way to fix the usability problems or to assess the quality of any redesigns. However, because of the way that heuristic evaluation results are composed, it will often be fairly easy to modify design or fix many usability problems according to the guidelines provided by them.
Heuristic evaluation is explicitly intended as a "discount usability engineering" method. Independent research (Jeffriesal. 1991) has indeed confirmed that heuristic evaluation is a very efficient usability engineering method. As a discount usability engineering method, heuristic evaluation is not guaranteed to provide "perfect" results or to find every last usability problem in interface.
There are a few different collections of heuristics that can be used. During my research I decided to use twelve principles for good human-centred interactive systems designproposed by Benyon, Turner & Turner in 'Designing Interactive Systems' and also recommended during a lecture.
I have carried out a usability test of the website http: //
After conducting usability test of Derby City Council Website (http: // 3 participants managed to find 10 different usability problems. Regrettably 3 of them have been recognised as the ones of the highest severity and therefore need urgent attention. Inspected website is extremely complex and consists of numerous sub pages; this fact will undoubtedly make the changes extremely difficult to perform. It is worth noticing that the most severe problems were found in style and navigation and the best solution to eliminate them would be to redesign the whole system.