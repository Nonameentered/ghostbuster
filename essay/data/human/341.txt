Abstract: We empirically compare the efficiency of two Binary Search algorithms in a number-guessing task with feedback. The difference between the algorithms is the method used to guess a target item: one chooses an item in the midpoint of a range, whereas the other picks a random item within the range. We show that the former converges faster to the correct answer than the latter, as predicted by complexity theory.
Searching for a given item in a finite list is a common task in every day life. One searches for telephone numbers in a phonebook or words in a dictionary. In order to automate this process, one might create a computer program that runs sequentially through every word in the dictionary and asks the user whether the word in turn is the one she is looking for. Although this procedure would eventually find the target word, it would take a long time to do so. The time required to complete the task will depend on the relative position of the word in the dictionary: words in the beginning will be found faster than words toward the end. In fact, if the dictionary contains N words and if every look-up counts as one computation, then it would take at most N computations to complete the task. And the user would have to reply N times.
Fortunately, there is a way to improve the efficiency of the look-up procedure: pick a word in the dictionary and ask whether the target word is further up or down in the sequence; if it is up, delete the lower part; if it is down, delete the upper part; do the same until the target word is reached. This procedure is called Binary Search because each time a word is picked the procedure splits the search space into two parts and discards one of them. As intuitive as it seems, however, the Binary Search algorithm depends crucially on the criterion used to split the search space. Depending on the criterion chosen one might end up either with the optimal solution or the worst.
In this paper, we present a comparison between two algorithms that use Binary Search as their core procedure but differ slightly in the criterion used to split the search space: the first (binary search algorithm) always pick an item in the middle of the search space; the second (random search algorithm), by contrast, randomly chooses an item in the space. This difference is sufficient to change the worst-case complexity of the first algorithm from O(log N), the optimal solution, to O(N), the worst solution. In order to empirically test that, we compare the performance of both algorithms in a number-guessing task. We hypothesise that binary search will converge to the correct answer faster and more reliably than random search.
The main hypothesis is that binary search will converge faster to the target than random search. Specifically, the mean number of guesses in the first case should be sistematically smaller than in the second case. As Table 1 shows, binary search outperformed random search in all the ranges tested. In addition, binary search's performance varied much less than random search's performance, as suggested by the standard deviation scores.
The difference between the two algorithms becomes even more dramatic when one investigates their asymptotic behaviour. The ratio between the mean number of guesses of random search and binary search increases as N tends to infinity. The reason is that, for the former, the number of guesses will linearly increase with the size of the range, whereas for the latter, the number of guesses will increase slowly, following a logarithmic function. Figure 1 illustrates this behaviour: as expected, the two curves diverge as the range size increases (from range 1-800 onwards).
We have empirically tested two Binary Search algorithms and showed that, as expected by complexity theory, binary search outperforms random search. The result illustrates the idea that seemingly minor differences among algorithms can yield large differences in performance, ranging from the worst to the optimal solution.
The results from random search were also more variable than binary search. This was expected, as the split points differ from run to run. While the first guess in binary search is always 50, in random search, it can be any number within the range.
A possible criticism to the experiment is that the targets were not kept constant across algorithms (see Appendix for a sample output). What if the targets for random search were harder to guess than for binary search? Because the 100 targets in each experimental batch were chosen randomly, that possibility seems unlikely. Conversely, if targets were equal across conditions, then a similar point could be raised: that the targets could be easier for either condition. Once again, randomisation would render that possibility unlikely. Therefore, both designs are equivalent..