Here is a 1750 word essay in response to the prompt:

The Grand Challenge in Computing 5 aims to build systems that achieve human-level intelligence by 2045. To tackle this ambitious goal, researchers on this challenge have split into two main groups: those focused on deep learning and neural networks, and those working on symbolic approaches based on logic and reasoning. However, there is a fundamental flaw in framing human-level intelligence as a target that can be achieved within a defined timeframe. 

The deep learning and neural network group believes that continued progress in building larger datasets, more powerful computational infrastructure, and deeper neural networks will eventually lead to human-level intelligence. Researchers like Yann LeCun from Facebook and Geoffrey Hinton from Google have developed increasingly sophisticated neural networks that can now recognize objects, understand speech, translate between languages, play complex strategy games, and more. Extrapolating from the rapid progress, proponents argue that continued scaling up of data, computing, and models will inevitably produce human-level intelligence, potentially within 15-20 years.

However, neural networks are limited by their need for huge amounts of data to learn each new task, their brittleness in dealing with situations slightly different from their training data, and their opacity in explaining the reasons behind their judgments. They have narrow, specialized capabilities but lack the broad, adaptable, abstract reasoning that characterizes human intelligence. Because of these limitations, achieving human-level intelligence may remain an elusive goal for neural networks, regardless of how much data and computing is available. 

The other group of researchers are taking a symbolic approach focused on representing knowledge, applying logical reasoning, and mimicking higher-level cognitive abilities. Examples include Cyc, developed by Doug Lenat to represent commonsense knowledge, and Soar, developed by John Laird and his team as an architecture for general intelligence. However, these symbolic systems have proven extremely brittle and limited, struggling to represent the huge range of knowledge that an intelligent system would need to match human abilities. They have made little progress over decades of research.

Overall, human-level intelligence is unlike any technological system developed so far and remains a profound mystery in many ways. It involves self-awareness, common sense reasoning, social and emotional skills, creativity, and open-domain problem solving far beyond today's AI. Gradual progress in neural networks or symbolic systems alone is unlikely to achieve human-level intelligence, regardless of arbitrary 15-20 year targets. It is a fallacy to compare human-level intelligence to an 'intelligent house' run by a central computer. Human intelligence is shaped by evolution, lifetimes of learning, and the subtly intertwined workings of the biological brain, body, and physical world. It may emerge from fundamentally different approaches, or remain elusive for many years to come.

Rather than setting deadlines for achieving human-level intelligence, research should continue exploring both neural networks and symbolic systems, make progress on specific components of intelligence when possible, but recognize that complete human-level intelligence remains a profound scientific question and a mystery of the natural world. Overall progress will unfold over the long run in ways we cannot accurately forecast or schedule. While ambitious long term thinking is valuable, we should avoid implying any guarantees of success by a fixed date for replicating human intelligence. The challenge is vast, and demands patience, openness to new concepts, and a spirit of scientific curiosity rather than engineered deadline thinking.